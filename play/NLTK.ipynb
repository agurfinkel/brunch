{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/arie/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/arie/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82115"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wn.all_synsets('n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18156"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(wn.all_synsets('a')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greyback', 'grayback', 'Limnodromus_griseus']\n",
      "['pharyngeal_tonsil', 'adenoid', \"Luschka's_tonsil\", 'third_tonsil', 'tonsilla_pharyngealis', 'tonsilla_adenoidea']\n",
      "['Dipnoi', 'subclass_Dipnoi']\n",
      "['alexandrite']\n",
      "['Australian_cockroach', 'Periplaneta_australasiae']\n",
      "['skull']\n",
      "['Spode']\n",
      "['dolmen', 'cromlech', 'portal_tomb']\n",
      "['marasca', 'marasca_cherry', 'maraschino_cherry', 'Prunus_cerasus_marasca']\n",
      "['Dactyloctenium', 'genus_Dactyloctenium']\n",
      "['firstborn', 'eldest']\n",
      "['Globicephala', 'genus_Globicephala']\n",
      "['Hubble', 'Edwin_Hubble', 'Edwin_Powell_Hubble']\n",
      "['seborrhea']\n",
      "['transsexual', 'transexual']\n",
      "['siren']\n",
      "['Gorgon']\n",
      "['South']\n",
      "['genus_Difflugia']\n",
      "['place']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for synset in random.sample(list(wn.all_synsets('n')), 20):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unusual']\n",
      "['bisexual']\n",
      "['uncool']\n",
      "['ecumenic', 'oecumenic', 'ecumenical', 'oecumenical']\n",
      "['shamanist', 'shamanistic']\n",
      "['high-ceilinged']\n",
      "['bawdy', 'off-color', 'ribald']\n",
      "['necklike']\n",
      "['Merovingian']\n",
      "['pearl_grey', 'pearl_gray']\n",
      "['high-fidelity', 'hi-fi']\n",
      "['chartless', 'uncharted', 'unmapped']\n",
      "['parted']\n",
      "['coral']\n",
      "['unarmed']\n",
      "['Frisian']\n",
      "['abusive']\n",
      "['denotative', 'explicit']\n",
      "['promotional']\n",
      "['soled']\n"
     ]
    }
   ],
   "source": [
    "for synset in random.sample(list(wn.all_synsets('a')), 20):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity\n",
      "physical_entity\n",
      "abstraction\n",
      "thing\n",
      "object\n",
      "whole\n",
      "congener\n",
      "living_thing\n",
      "organism\n",
      "benthos\n"
     ]
    }
   ],
   "source": [
    "for synset in list(wn.all_synsets('n'))[:10]:\n",
    "    print(synset.lemma_names()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "alphanum = re.compile(r'^[^\\d]\\w+$')\n",
    "def printable(s):\n",
    "    return len(s) >= 3 and alphanum.match(s) is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = [ln for s in list(wn.all_synsets('a')) for ln in s.lemma_names()]\n",
    "adjectives = list(filter(printable, adjectives))\n",
    "nouns = [ln for s in list(wn.all_synsets('n')) for ln in s.lemma_names()]\n",
    "nouns = list(filter(printable, nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nouns.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(nouns, fp)\n",
    "with open('adjectives.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(adjectives, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (importlib.resources.files(words) / 'nouns.json').open('r') as nouns:\n",
    "    wnouns = json.load(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (importlib.resources.files(words) / 'adjectives.json').open('r') as ajd:\n",
    "    wadj = json.load(ajd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139907, 26577)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wnouns), len(wadj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'genip'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.get_a_noun(length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harsh'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.get_an_adjective(length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26577\n",
      "1110\n"
     ]
    }
   ],
   "source": [
    "import words.common\n",
    "adj = words.common.get_adjectives()\n",
    "print(len(adj))\n",
    "print(len(list(filter(lambda s : len(s) == 4, adj))))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
